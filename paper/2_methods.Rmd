<!-- The experiment was conducted from July 2014 to November 2014.  -->
<!--  Message was three times: at the launch of the submission phase, eight days from the launch and two days before the end of the submission phase of the challenge. -->

# Context, experimental design, data
## Context

The medical organization in which the experiment was carried out is the Massachusetts General Hospital's (MGH) Corrigan Minehan Heart Center, or the  "Heart Center" for short. Founded more than a hundred years ago, the Heart Center is a prominent medical organization in the United States and a teaching hospital of the Harvard Medical School. It serves thousands of patients every year, occupies more than 35,000 square feet of office space, and employs more than 1,200 people (nurses, physicians, researchers, technicians, and administrative staff) scattered across several buildings on the MGH's main campus in downtown Boston and a few other satellite locations.

The opportunity for this study was the Heart Center's launch of the Healthcare Transformation Lab (HTL), an initiative aimed at developing innovative healthcare process improvements to enhance the healthcare safety and delivery of the hospital.^[See the HTL's web site at: www.healthcaretransformation.org] The launch of the HTL was accompanied by the announcement of an internal innovation contest, called the Ether Dome Challenge,[^EDC] that sought to engage all staff members to participate.

[^EDC]: The name is taken from a historical place on MGH's main campus where the first public surgery using anesthesia was demonstrated in 1846.] 

The communication around the innovation contest highlighted the opportunity for staff to help in the selection process of the ideas and a commitment by the Heart Center Management that the leading ideas would be provided appropriate resources so that they could be implemented. The announcement on the contest website reads:

> "If you've noticed something about patient experience, employee satisfaction, workplace efficiency, or anything that could be improved; if you've had an inspiration about a new way to safeguard health; or if you simply have a cost-saving idea, then now is the time to share your idea."

Within this context, we worked with the HTL administrators to design the innovation contest and the experimental treatments that were then randomly assigned to all staff members of the Heart Center in order to identify and compare the effect of different motivations on employee participation in the contest. 

\begin{figure}
\centering
\caption{Timeline of the innovation contest}
\label{timeline}
\includegraphics{../figs/timeline.pdf}
\end{figure}

The innovation contest can be divided into three main phases (Figure \ref{timeline}). The first is a four-week submission phase in which all staff members are encouraged to identify one or more organizational problems and submit proposals addressing them. Employee participation is voluntary and all project submissions can be done online via the website of the contest.  There is no limit in the number of project proposals to submit and proposals could cover any issue within the organization. The only constraints are: (1) each proposal is limited to approximately 300 words to lower the costs of entry and encourage broader participation; and (2) team submissions are not permitted. The second constraint is to ensure that randomly assigned treatment effects, which we describe next, could be isolated, identified, and matched to individual participants. Another advantage of the individual submission constraint is that it lowers the incentives to communicate or exchange information among employees by preventing groups to form, thus lowering the risk of "interference" among individuals in the different treatments, a problem we will discuss later. In addition, the website provides no feedback information about the status of the contest during the submission period, so that individual decisions could not be easily influenced by the perceived popularity of the contest or previous submissions.

The second is a two-week project evaluation phase in which all staff members are invited to rate the merit and potential of submitted proposals on a five-point rating scale. Such evaluations are done on the website of the contest where each evaluator is shown a list of anonymized proposals to read and rate. Proposals are presented in batches of 10 each and in random order to ensure an even exposure. Each proposal is described by a title, a main description of the problem to solve, and the proposal. Voting is then introduced by the following text: "Rate this idea" followed by the rating scale: 1-low; 2; 3; 4; 5-high. Evaluators can decide how many proposals to rate and they get a chance to win a limited edition T-shirt as a compensation for their efforts. Ratings would be kept confidential. And, as in the submission phase, the website provides no feedback or any other kind of information that would influence individual judgment until the evaluation phase is over. 

The third is an implementation phase in which employees having submitted proposals that would have been highly rated by peers and judged as particularly promising by the HTL staff are invited to submit a full proposal detailing plans for implementation. Following evaluation by MGH senior leadership, top proposals are then selected to receive support and funding for implementation. This final phase takes a few months to complete, essentially the time necessary to select and implement the best projects.

## Experimental design

Our experiment was conducted during the normal operations of the Heart Center. The basic idea of the experiment is to randomize the content of the communication announcing the innovation contest to all staff members. The start of the submission phase was indeed announced to everyone in a series of personalized emails. A direct message was sent to each contact in the list of employees' emails from our subject pool. The content of this communication with a placeholder for our solicitation treatment is reported below:^[An image of the exact email is in the Appendix.] 

> Dear Heart Center team member,
>    
> **Submit your ideas to [TREATMENT HERE]**
>    
> The Ether Dome Challenge is your chance to submit ideas on how to improve the MGH Corrigan Minehan Heart Center, patient care and satisfaction, workplace efficiency and cost. All Heart Center Staff are eligible to submit ideas online. We encourage you to submit as many ideas as you have: no ideas are too big or too small!
>
> Submissions will be reviewed and judged in two rounds, first by the Heart Center staff via crowd-voting, and then by an expert panel. Winning ideas will be eligible for project implementation funding in the Fall of 2014!

The first paragraph of the above message was randomized into _four_ different solicitation treatments, thus creating as many treatment groups of equal size. The first solicitation (PRIZE) announced the innovation contest as an opportunity to win individual awards (iPad mini's) for top submissions. The second solicitation  (FUND) announced the opportunity for participants to win a $20,000 budget for developing their own project proposals. The other solicitations announced the contest as an opportunity to improve the health care of their patients (PCARE) or the workplace (WPLACE), without mentioning any particular personal award for the winners (neither a prize nor the opportunity to lead the implementation of own projects). In Table \ref{experimental-design}, we report the exact words and randomly assigned employees for each solicitation treatment. 

\input{../tables/design.tex}

A sample size of more than 300 units for each treatment group ensured a sufficiently high statistical power based upon standard power calculations on the difference of proportions. In testing the difference of proportions between any two treatments, the probability of type-I errors was slightly below $0.80$ for _small_ differences at 5 percent significance level but higher than $0.80$ for _medium_ and _large_ differences at the more stringent 1 percent significance level.^[The definition of small, medium and large differences is given by @cohen1992power;  e.g., a difference of 5 percentage points of the pair $(0.05, 0.10)$ is considered a small effect: see @cohen1992power p. 158.]

Also, note the lack of a traditional "control" treatment in this study. Since the experiment was run in a workplace, we were constrained to carry out treatments having equal chances of being successful. This prevented us from having a 'null' treatment with no personalized incentives messaging as a control group. Indeed, the analysis focused on multiple comparisons of several unordered discrete treatments (e.g., prizes vs funding vs framing).^[Nevertheless, if we were to think of one treatment as the benchmark against which to compare the others, the FUND treatment would be our best candidate because that is the default option for announcing internal grant programs and was part of the HTL's initial design before our cooperation in the experiment.]

These solicitation messages were sent three times: at the launch of the submission phase, eight days from the launch and two days before the end of the submission phase of the challenge.

The website of the innovation contest had supporting information about the available prizes, funding, and timing of the initiative. The website also required an institutional email address to login. Using this feature, we designed the website graphics and layout to reinforce the effect of the announcement: the headings, background images, a short video, and the space just below a "submit your ideas" button were designed to show the exact same first paragraph of the solicitation that the employee received by email (i.e., text in Table \ref{experimental-design}).

The MGH management and the HTL staff members were blind to group assignment, which prevented potential bias in the communication of the innovation contest that was not under our direct control. We also made an effort to create a "safe" environment for employees submitting proposals by making clear (in the application form) that the identity of the proponents was going to be kept private unless the employee self-identified, so that management could not identify workers without their consent.

Finally, we relied only on official channels for communication to strengthen the effect of the announcement and signal legitimacy of the contest. Each employee received the same exact solicitation email three times: at the launch, eight days from the launch and two days before the end of the submission phase of the challenge. Starting from the second week of the submission phase, information booths, flyers, and posters were used to encourage everyone to take part in the event and respond to the email solicitation. These flyers and posters were based on a generic, undifferentiated version of the solicitation email without the text of the treatments.


## Data

```{r}
pc_admins    <- round(100*mean(hc$job=='Other'))
pc_doctors    <- round(100*mean(hc$job=='MD/Fellow'))
pc_women    <- round(100*mean(hc$gender=='female'))
pc_nurses   <- round(100*mean(hc$job=='Nursing'))
pc_women_nurses <- round(100*mean(hc$gender[hc$job=='Nursing']=='female'))
n_survey    <- sum(hc$has_survey=='yes')
pc_survey   <- round(100*mean(hc$has_survey=='yes'))
pc_office <- round(100*mean(hc$has_office=='yes'))

# Difference in tenure by office
tenure.by.office <- tapply(hc$tenure, hc$has_office, median, na.rm=TRUE)
```

Our subject pool is the entire population working at the Heart Center as of the end of 2014, a total of `r format(nrow(hc), big.mark=',')` individuals. For each individual, we have administrative data on the gender, the type of profession, and whether they had a fixed office location or not. Additional, complementary data are available for a limited group of `r n_survey` employees (`r pc_survey` percent) with self-reported demographics information, such as age and years of tenure at the Heart Center, that are from an online survey conducted about two months prior to the launch of the innovation contest. 

\input{../tables/summary.tex}

We report summary statistics for the different variables (Table \ref{summary-statistics}). A series of Chi-square tests of associations between treatment groups and each separate variable fail to reject the null hypothesis of independence; meaning that differences across groups are not attributable to our experimental intervention. In other words, treatment groups are statistically balanced.  

The data also show that the large majority (`r pc_women` percent) of employees in our sample are women. This is due to the high fraction of workers being nurses (`r pc_nurses` percent) and the presence of a gender separation by profession with nurses being predominantly women (`r pc_women_nurses` percent). 

As much of the clinical staff might be mobile, only half of the employees (`r pc_office` percent) have fixed office locations because they may be on duty in multiple wards. The need of being mobile, however, is not the same across professions. Nurses, for instance, are more likely to being assigned to a ward than physicians or administrative workers, due to the nature of their job. Within each profession, however, having a fixed office location is usually correlated with experience and hierarchical position inside the organization. Using our subset with tenure information, a staff member with a fixed office location has `r diff(tenure.by.office)` more years of tenure in median compared to an employee assigned to a ward; and the difference goes up to more than 3 years when we examine each professional category separately.

Differences in income and education are other important differences across professions. Though we do not have data on income, there exist large differences in earnings across professions. According to the United States Bureau of Labor Statistics, the median annual wage of a physician was $187,200 in 2015, which is about 60 percent higher than the that of a registered nurse ($67,490) and about 70 percent higher than that of a laboratory technician ($38,970). It follows that, if staff members are motivated by the extrinsic value of the prize alone, one should expect large differences in participation rates across profession.

Our main response variables include all the submissions to the contest, participation in the evaluation phase, and the resulting ratings for each project proposal as a measure of proposal quality. Basic summary statistics (Table \ref{outcomes}) show the overall participation in the submission phase is 5 percent of our sample with 60 submissions and a total of 118 project proposals (an average of 2 project proposals per submission). A 5 participation rate is unsurprising when one considers a few key elements, such as the busy environment, the fact that staff members have many conflicting priorities, and the foreseeable additional costs of leading implementation of a winning proposal. This result, however, does not imply that the overall participation in the contest was modest. On the contrary, when we combine data from the submission and evaluation phases, the overall participation rate is 16 percent.^[This is the union of employees who made submissions and evaluated proposals.] This means that about 1 out of 5 staff members was engaged in one way or another in the contest, indicating a good participation overall. 

\input{../tables/summary.outcomes.tex}







